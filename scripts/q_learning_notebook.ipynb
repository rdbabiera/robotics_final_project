{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to Train DQN Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Import ML Libraries\n",
    "from collections import namedtuple, deque\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torch.distributions as distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./models/\"\n",
    "\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'reward', 'next_state'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity, batch_size):\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "        self.capacity = capacity\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self):\n",
    "        return random.sample(self.memory, self.batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Reward System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Balloon(object):\n",
    "    def __init__(self, center, radius):\n",
    "        self.center = center\n",
    "        self.radius = radius\n",
    "\n",
    "    def determine_hit(self, coords):\n",
    "        dist = np.linalg.norm(self.center - coords)\n",
    "        if dist <= self.radius:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def determine_prize(self, coords, prev_coords, shape):\n",
    "        dist = np.linalg.norm(self.center - coords)\n",
    "        prize = 176 - (2 * self.radius)\n",
    "        scaling = 1 - (dist / self.radius)\n",
    "        h_flick = abs(prev_coords[0] - coords[0]) / (0.5 * shape[0])\n",
    "        w_flick = abs(prev_coords[1] - coords[1]) / (0.5 * shape[1])\n",
    "        prize += min(h_flick * 50, 50) + min(w_flick * 50, 50)\n",
    "\n",
    "        return prize * scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game(object):\n",
    "    def __init__(self, h, w):\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "        self.screen = torch.zeros((1, 1, self.h, self.w))\n",
    "        self.current_balloons = {}\n",
    "        self.last_shot = np.array([self.h//2, self.w//2])\n",
    "\n",
    "        for i in range(0, 3):\n",
    "            rad = np.random.randint(38, 80)\n",
    "\n",
    "            y_coord = np.random.randint(20, self.h-20)\n",
    "            x_coord = np.random.randint(20, self.w-20)\n",
    "            pos = np.array([x_coord, y_coord])\n",
    "\n",
    "            bloon = Balloon(pos, rad)\n",
    "\n",
    "            print(\"Adding Balloon\")\n",
    "\n",
    "            for y in range(y_coord - rad, y_coord + rad):\n",
    "                if y < 0 or y >= self.h:\n",
    "                    continue\n",
    "                for x in range(x_coord - rad, x_coord + rad):\n",
    "                    if x < 0 or x >= self.w:\n",
    "                        continue\n",
    "                    curr = np.array([y, x])\n",
    "                    if np.linalg.norm(pos - curr) <= rad:\n",
    "                        self.screen[0, 0, y, x] = 1\n",
    "\n",
    "            self.current_balloons[i] = bloon\n",
    "        \n",
    "        self.done = False\n",
    "\n",
    "    def update_shot(self, action):\n",
    "        action = action.numpy()\n",
    "        max_action = np.where(action == np.amax(action))\n",
    "        action = np.array([max_action[2][0], max_action[3][0]])\n",
    "\n",
    "        reward = 0\n",
    "\n",
    "        to_remove = []\n",
    "\n",
    "        for i in self.current_balloons:\n",
    "            balloon = self.current_balloons[i]\n",
    "            if balloon.determine_hit(action):\n",
    "                print(\"balloon hit!\")\n",
    "\n",
    "                # Determine Reward\n",
    "                reward += balloon.determine_prize(action, self.last_shot, np.array([self.h, self.w]))\n",
    "\n",
    "                # Remove From Grid/Dictionary\n",
    "                for y in range(balloon.center[0] - balloon.radius, balloon.center[0] + balloon.radius):\n",
    "                    if y < 0 or y >= self.h:\n",
    "                        continue\n",
    "                    for x in range(balloon.center[1] - balloon.radius, balloon.center[1] + balloon.radius):\n",
    "                        if x < 0 or x >= self.w:\n",
    "                            continue\n",
    "                        self.screen[0, 0, y, x] = 0\n",
    "\n",
    "                to_remove.append(i)\n",
    "        \n",
    "        for idx in to_remove:\n",
    "            self.current_balloons.pop(idx)\n",
    "\n",
    "        self.last_shot = action\n",
    "\n",
    "        next_state = self.screen\n",
    "\n",
    "        if len(self.current_balloons) == 0:\n",
    "            self.done = True\n",
    "            print(\"All balloons popped!\")\n",
    "\n",
    "        return torch.tensor(reward), next_state, self.done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AimlabNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AimlabNetwork, self).__init__()\n",
    "        self.input_channels = 1\n",
    "        self.output_channels = 1\n",
    "        self.hidden_size_1 = 32\n",
    "        self.hidden_size_2 = 64\n",
    "        self.hidden_size_3 = 128\n",
    "\n",
    "        self.encoder = nn.ModuleList([\n",
    "            #--- Stage 1\n",
    "            nn.Conv2d(self.input_channels, self.hidden_size_1, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(self.hidden_size_1), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.hidden_size_1, self.hidden_size_1, kernel_size=3, padding=1), \n",
    "            nn.BatchNorm2d(self.hidden_size_1), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, return_indices = True), \n",
    "            #--- Stage 2\n",
    "            nn.Conv2d(self.hidden_size_1, self.hidden_size_2, kernel_size=3, padding=1), \n",
    "            nn.BatchNorm2d(self.hidden_size_2), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.hidden_size_2, self.hidden_size_2, kernel_size=3, padding=1), \n",
    "            nn.BatchNorm2d(self.hidden_size_2), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.hidden_size_2, self.hidden_size_2, kernel_size=3, padding=1), \n",
    "            nn.BatchNorm2d(self.hidden_size_2), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, return_indices = True), \n",
    "            #--- Stage 3\n",
    "            nn.Conv2d(self.hidden_size_2, self.hidden_size_3, kernel_size=3, padding=1), \n",
    "            nn.BatchNorm2d(self.hidden_size_3), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.hidden_size_3, self.hidden_size_3, kernel_size=3, padding=1), \n",
    "            nn.BatchNorm2d(self.hidden_size_3), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.hidden_size_3, self.hidden_size_3, kernel_size=3, padding=1), \n",
    "            nn.BatchNorm2d(self.hidden_size_3), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, return_indices = True)\n",
    "        ])\n",
    "\n",
    "        self.decoder = nn.ModuleList([                                              \n",
    "            #--- Stage 3-2\n",
    "            nn.MaxUnpool2d(kernel_size=2, stride=2), \n",
    "            nn.ConvTranspose2d(self.hidden_size_3, self.hidden_size_3, kernel_size=3, padding=1), \n",
    "            nn.BatchNorm2d(self.hidden_size_3),\n",
    "            nn.ReLU(),  \n",
    "            nn.ConvTranspose2d(self.hidden_size_3, self.hidden_size_3, kernel_size=3, padding=1), \n",
    "            nn.BatchNorm2d(self.hidden_size_3), \n",
    "            nn.ReLU(),               \n",
    "            nn.ConvTranspose2d(self.hidden_size_3, self.hidden_size_2, kernel_size=3, padding=1), \n",
    "            nn.BatchNorm2d(self.hidden_size_2), \n",
    "            nn.ReLU(),\n",
    "            #--- Stage 2-2\n",
    "            nn.MaxUnpool2d(kernel_size=2, stride=2),\n",
    "            nn.ConvTranspose2d(self.hidden_size_2, self.hidden_size_2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(self.hidden_size_2), \n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(self.hidden_size_2, self.hidden_size_2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(self.hidden_size_2), \n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(self.hidden_size_2, self.hidden_size_1, kernel_size=3, padding=1), \n",
    "            nn.BatchNorm2d(self.hidden_size_1), \n",
    "            nn.ReLU(),\n",
    "            #--- Stage 1-2\n",
    "            nn.MaxUnpool2d(kernel_size=2, stride=2), \n",
    "            nn.ConvTranspose2d(self.hidden_size_1, self.hidden_size_1, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(self.hidden_size_1), \n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(self.hidden_size_1, self.output_channels, kernel_size=3, padding=1), \n",
    "            nn.BatchNorm2d(self.output_channels), \n",
    "            nn.Sigmoid()\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        stack = []\n",
    "        # Forward\n",
    "        out = x\n",
    "        for i, l in enumerate(self.encoder):\n",
    "            if isinstance(l, nn.MaxPool2d): \n",
    "                out, indices = l(out)\n",
    "                stack.append(indices)\n",
    "            else:\n",
    "                out = l(out)\n",
    "        \n",
    "        # Backward\n",
    "        for i, l in enumerate(self.decoder):\n",
    "            if isinstance(l, nn.MaxUnpool2d): \n",
    "                indices = stack.pop()\n",
    "                out = l(out, indices)\n",
    "            else:\n",
    "                out = l(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AimlabTrainer(object):\n",
    "    def __init__(self, h, w):\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "\n",
    "        \"\"\"\n",
    "        Model Parameters\n",
    "        \"\"\"\n",
    "        self.batch_size = 1\n",
    "        self.gamma = 0.999\n",
    "        self.eps_start = 0.9\n",
    "        self.eps_end = 0.05\n",
    "        self.eps_decay = 200\n",
    "        self.target_update = 10\n",
    "\n",
    "        self.steps_done = 0\n",
    "\n",
    "        self.model = AimlabNetwork()\n",
    "        self.target_model = AimlabNetwork()\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "        self.target_model.eval()\n",
    "\n",
    "        self.memory = ReplayMemory(10, 1)\n",
    "        self.optimizer = optim.RMSprop(self.model.parameters())\n",
    "\n",
    "\n",
    "    def select_action(self, state):\n",
    "        sample = random.random()\n",
    "        eps_threshold = self.eps_end + (self.eps_start - self.eps_end) * \\\n",
    "            math.exp(-1. * self.steps_done / self.eps_decay)\n",
    "        self.steps_done += 1\n",
    "        if sample > eps_threshold:\n",
    "            action = self.model(state).detach()\n",
    "        else:\n",
    "            action = torch.rand((self.batch_size, 1, self.h, self.w), dtype=torch.float64)\n",
    "        return action\n",
    "    \n",
    "\n",
    "    def optimize(self):\n",
    "        if len(self.memory) < self.memory.capacity:\n",
    "            return\n",
    "        transitions = self.memory.sample()\n",
    "        batch = Transition(*zip(*transitions))\n",
    "\n",
    "        next_state_batch = batch.next_state[0]\n",
    "        state_batch = batch.state[0]\n",
    "        action_batch = batch.action[0]\n",
    "        reward_batch = batch.reward[0]                          \n",
    "\n",
    "        # Compute Q(s_t, a)\n",
    "        state_action_values = self.model(state_batch)\n",
    "\n",
    "        # Compute V(s_{t+1}) for all next states.\n",
    "        next_state_values = self.target_model(next_state_batch).detach()\n",
    "        # Compute expected Q\n",
    "        expected_state_action_values = (next_state_values * self.gamma) + reward_batch\n",
    "        \n",
    "        # Compute Huber loss\n",
    "        criterion = nn.SmoothL1Loss()\n",
    "        loss = criterion(state_action_values, expected_state_action_values)\n",
    "\n",
    "        # Optimize Model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in self.model.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        self.optimizer.step()\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        num_episodes = 1\n",
    "        for i_episode in range(num_episodes):\n",
    "            if i_episode % 2 == 0:\n",
    "                print(f\"Starting Episode {i_episode}\")\n",
    "\n",
    "            game = Game(self.h, self.w)\n",
    "            state = game.screen\n",
    "            \n",
    "            done = False\n",
    "            while not done:\n",
    "                action = self.select_action(state)\n",
    "                reward, next_state, done = game.update_shot(action)\n",
    "\n",
    "                # Store Transition in Memory\n",
    "                self.memory.push(state, action, reward, next_state)\n",
    "\n",
    "                # Move to Next State\n",
    "                state = next_state\n",
    "\n",
    "                # Perform Optimization\n",
    "                self.optimize()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Episode 0\n",
      "Adding Balloon\n",
      "Adding Balloon\n",
      "Adding Balloon\n",
      "balloon hit!\n",
      "torch.Size([1, 1, 480, 640])\n",
      "torch.Size([1, 1, 480, 640])\n",
      "torch.Size([1, 1, 480, 640])\n",
      "torch.Size([1, 1, 480, 640])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19132/1735942017.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAimlabTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m480\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m640\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19132/2926602136.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[1;31m# Perform Optimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19132/2926602136.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;31m# Optimize Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclamp_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rdbab\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rdbab\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = AimlabTrainer(480, 640)\n",
    "model.train()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0be040c72e6ce70a970e5aa555bba4e94a93058868494b22b955227bc094c34"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
